{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c59e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datastreams import generate_crypto_time_series\n",
    "from models import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from driftdetector import DriftDetector\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "803fd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, seq_len):\n",
    "    time_series = []\n",
    "    for i in range(len(data) - seq_len + 1):\n",
    "        time_series.append(data[i:i + seq_len])\n",
    "    return np.array(time_series)[:-1], data[seq_len:], data[seq_len-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8609c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_lr_only(optimizer, drifted, decay_state, factor=2.0, max_lr=0.01):\n",
    "    if drifted:\n",
    "        for i, pg in enumerate(optimizer.param_groups):\n",
    "            base_lr = decay_state['base_lrs'][i]\n",
    "            pg['lr'] = min(base_lr * factor, max_lr)\n",
    "\n",
    "def increase_and_decay_lr(optimizer, drifted, decay_state, factor=2.0, decay_steps=10):\n",
    "    base_lrs = decay_state['base_lrs']\n",
    "    \n",
    "    if drifted:\n",
    "        for i, pg in enumerate(optimizer.param_groups):\n",
    "            pg['lr'] = base_lrs[i] * factor\n",
    "        decay_state['current_decay_step'] = decay_steps\n",
    "\n",
    "    elif decay_state['current_decay_step'] > 0:\n",
    "        decay_state['current_decay_step'] -= 1\n",
    "        for i, pg in enumerate(optimizer.param_groups):\n",
    "            boosted_lr = base_lrs[i] * factor\n",
    "            ratio = decay_state['current_decay_step'] / decay_steps\n",
    "            pg['lr'] = base_lrs[i] + (boosted_lr - base_lrs[i]) * ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39406804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, detector, x_all, y_all, optimizer, loss_fn, device, drift_action):\n",
    "\n",
    "    model.train()\n",
    "    preds = []\n",
    "    all_loss = []\n",
    "\n",
    "    # For drift action state\n",
    "    base_lrs = [pg['lr'] for pg in optimizer.param_groups]\n",
    "    decay_state = {\n",
    "        'base_lrs': base_lrs,\n",
    "        'current_decay_step': 0\n",
    "    }\n",
    "\n",
    "    step = 0\n",
    "    mae_values = []\n",
    "    mae_values_full = []\n",
    "\n",
    "    for x, y in zip(x_all, y_all):\n",
    "        step += 1\n",
    "        x_ten = torch.tensor(x, dtype=torch.float32).view(1, -1).to(device)\n",
    "        y_ten = torch.tensor(y, dtype=torch.float32).view(1, -1).to(device)\n",
    "        # Training step\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_ten)\n",
    "        preds.append(pred.item())\n",
    "        loss = loss_fn(pred, y_ten)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_loss.append(loss.item())\n",
    "\n",
    "        # Drift handling\n",
    "        if detector.update(loss.item()):\n",
    "            drift_action(optimizer, drifted=True, decay_state=decay_state)\n",
    "\n",
    "        drift_action(optimizer, drifted=False, decay_state=decay_state)\n",
    "        \n",
    "        mae_full = torch.abs(pred - y_ten).mean().item()\n",
    "        mae_values_full.append(mae_full)\n",
    "\n",
    "        # Post-warmup MAE tracking\n",
    "        if step >= 200:\n",
    "            mae_values.append(mae_full)\n",
    "\n",
    "    avg_loss = sum(all_loss) / len(all_loss) if all_loss else 0.0\n",
    "    avg_mae_post_warmup = sum(mae_values) / len(mae_values) if mae_values else 0.0\n",
    "    avg_mae_full = sum(mae_values_full) / len(mae_values_full) if mae_values_full else 0.0\n",
    "\n",
    "\n",
    "    return model, avg_loss, avg_mae_post_warmup, avg_mae_full, preds\n",
    "\n",
    "def simulate(prices, preds):\n",
    "    budget = 100\n",
    "    amount = 0\n",
    "    max_budget = 100\n",
    "    for i in range(len(prices)):\n",
    "        if preds[i] > prices[i] and amount == 0:\n",
    "            amount = budget / prices[i]\n",
    "        if preds[i] < prices[i] and amount > 0:\n",
    "            budget = amount * prices[i]\n",
    "            amount = 0\n",
    "\n",
    "        if budget > max_budget:\n",
    "            max_budget = budget\n",
    "\n",
    "    return budget, max_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87f01b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64688bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"../data/btc_data.csv\", \"../data/eth_data.csv\"]\n",
    "detector_types = [\"ADWIN\", \"PageHinkley\"]\n",
    "drift_actions = [increase_lr_only, increase_and_decay_lr]\n",
    "seq_lens = [16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e711ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizess = [[16], [32, 32], [64, 64]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82e3782b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths) * len(detector_types) * len(drift_actions) * len(seq_lens) * len(hidden_sizess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37aea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    data = generate_crypto_time_series(path)\n",
    "    for detector_type in detector_types:\n",
    "        detector = DriftDetector(method=detector_type)\n",
    "        for drift_action in drift_actions:\n",
    "            for seq_len in seq_lens:\n",
    "                for hidden_sizes in hidden_sizess:\n",
    "                    x_all, y_all, prices = make_dataset(data, seq_len)\n",
    "                    model = TimeSeriesMLP(\n",
    "                        input_size=seq_len,\n",
    "                        hidden_sizes=hidden_sizes,\n",
    "                        output_size=1,\n",
    "                    )\n",
    "                    model.to(device)\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                    loss_fn = nn.MSELoss()\n",
    "                    model, loss, mae_full, mae_warmup, preds = train_model(\n",
    "                        model,\n",
    "                        detector,\n",
    "                        x_all,\n",
    "                        y_all,\n",
    "                        optimizer,\n",
    "                        loss_fn,\n",
    "                        device=device,\n",
    "                        drift_action=drift_action\n",
    "                    )\n",
    "                    budget, max_budget = simulate(prices, preds)\n",
    "                    # save stream, n_dim, n_points, detector_type, seq_len, hidden_sizes, train_loss, test_loss to CVS file\n",
    "                    with open(\"crypto_mlp.csv\", \"a\") as f:\n",
    "                        f.write(\n",
    "                            f\"{path.split(\"/\")[-1].split(\"_\")[0]};1;{len(data)};{detector_type};{seq_len};{hidden_sizes};{loss};{mae_full};{mae_warmup};{budget};{max_budget}\\n\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcce4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4887dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_crypto_time_series(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13765eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, seq_len):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaled_data = []\n",
    "\n",
    "    # Apply River's scaler in an online fashion\n",
    "    for x in data:\n",
    "        scaler.learn_one({'value': x})\n",
    "        x_scaled = scaler.transform_one({'value': x})['value']\n",
    "        scaled_data.append(x_scaled)\n",
    "\n",
    "    time_series = []\n",
    "    for i in range(len(scaled_data) - seq_len + 1):\n",
    "        time_series.append(scaled_data[i:i + seq_len])\n",
    "\n",
    "\n",
    "    return np.array(time_series[:-1]), np.array(data[seq_len:]), np.array(data[seq_len-1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef8dc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e64433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.learn_one({'value': data[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3184067f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform_one({'value': data[0]})['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75df38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63077e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = make_dataset(data, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3c7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28862d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
