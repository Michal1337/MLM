{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882b4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datastreams import generate_water_flow_data\n",
    "from models import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from driftdetector import DriftDetector\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "047f0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, seq_len):\n",
    "    time_series = []\n",
    "    for i in range(len(data) - seq_len + 1):\n",
    "        time_series.append(data[i:i + seq_len])\n",
    "    return np.array(time_series)[:-1], data[seq_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64fc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_lr_only(optimizer, drifted, decay_state, factor=2.0, max_lr=0.01):\n",
    "    if drifted:\n",
    "        for i, pg in enumerate(optimizer.param_groups):\n",
    "            base_lr = decay_state['base_lrs'][i]\n",
    "            pg['lr'] = min(base_lr * factor, max_lr)\n",
    "\n",
    "def increase_and_decay_lr(optimizer, drifted, decay_state, factor=2.0, decay_steps=10):\n",
    "    base_lrs = decay_state['base_lrs']\n",
    "    \n",
    "    if drifted:\n",
    "        for i, pg in enumerate(optimizer.param_groups):\n",
    "            pg['lr'] = base_lrs[i] * factor\n",
    "        decay_state['current_decay_step'] = decay_steps\n",
    "\n",
    "    elif decay_state['current_decay_step'] > 0:\n",
    "        decay_state['current_decay_step'] -= 1\n",
    "        for i, pg in enumerate(optimizer.param_groups):\n",
    "            boosted_lr = base_lrs[i] * factor\n",
    "            ratio = decay_state['current_decay_step'] / decay_steps\n",
    "            pg['lr'] = base_lrs[i] + (boosted_lr - base_lrs[i]) * ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f2169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, detector, x_all, y_all, optimizer, loss_fn, device, drift_action):\n",
    "\n",
    "    model.train()\n",
    "    all_loss = []\n",
    "\n",
    "    # For drift action state\n",
    "    base_lrs = [pg['lr'] for pg in optimizer.param_groups]\n",
    "    decay_state = {\n",
    "        'base_lrs': base_lrs,\n",
    "        'current_decay_step': 0\n",
    "    }\n",
    "\n",
    "    step = 0\n",
    "    mae_values = []\n",
    "    mae_values_full = []\n",
    "\n",
    "    for x, y in zip(x_all, y_all):\n",
    "        step += 1\n",
    "        x_ten = torch.tensor(x, dtype=torch.float32).view(1, -1).to(device)\n",
    "        y_ten = torch.tensor(y, dtype=torch.float32).view(1, -1).to(device)\n",
    "        # Training step\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_ten)\n",
    "        loss = loss_fn(pred, y_ten)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_loss.append(loss.item())\n",
    "\n",
    "        # Drift handling\n",
    "        if detector.update(loss.item()):\n",
    "            drift_action(optimizer, drifted=True, decay_state=decay_state)\n",
    "\n",
    "        drift_action(optimizer, drifted=False, decay_state=decay_state)\n",
    "        \n",
    "        mae_full = torch.abs(pred - y_ten).mean().item()\n",
    "        mae_values_full.append(mae_full)\n",
    "\n",
    "        # Post-warmup MAE tracking\n",
    "        if step >= 200:\n",
    "            mae_values.append(mae_full)\n",
    "\n",
    "    avg_loss = sum(all_loss) / len(all_loss) if all_loss else 0.0\n",
    "    avg_mae_post_warmup = sum(mae_values) / len(mae_values) if mae_values else 0.0\n",
    "    avg_mae_full = sum(mae_values_full) / len(mae_values_full) if mae_values_full else 0.0\n",
    "\n",
    "\n",
    "    return model, avg_loss, avg_mae_post_warmup, avg_mae_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e1fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b833b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_types = [\"ADWIN\", \"PageHinkley\"]\n",
    "drift_actions = [increase_lr_only, increase_and_decay_lr]\n",
    "seq_lens = [16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e87168",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizess = [[16], [32, 32], [64, 64]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc33e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detector_types) * len(drift_actions) * len(seq_lens) * len(hidden_sizess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_water_flow_data()\n",
    "for detector_type in detector_types:\n",
    "    detector = DriftDetector(method=detector_type)\n",
    "    for drift_action in drift_actions:\n",
    "        for seq_len in seq_lens:\n",
    "            for hidden_sizes in hidden_sizess:\n",
    "                x_all, y_all = make_dataset(data, seq_len)\n",
    "                model = TimeSeriesMLP(\n",
    "                    input_size=seq_len,\n",
    "                    hidden_sizes=hidden_sizes,\n",
    "                    output_size=1,\n",
    "                )\n",
    "                model.to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                loss_fn = nn.MSELoss()\n",
    "                model, loss, mae_full, mae_warmup = train_model(\n",
    "                    model,\n",
    "                    detector,\n",
    "                    x_all,\n",
    "                    y_all,\n",
    "                    optimizer,\n",
    "                    loss_fn,\n",
    "                    device=device,\n",
    "                    drift_action=drift_action\n",
    "                )\n",
    "                # save stream, n_dim, n_points, detector_type, seq_len, hidden_sizes, train_loss, test_loss to CVS file\n",
    "                with open(\"wf_mlp.csv\", \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"{generate_water_flow_data.__name__};1;{len(data)};{detector_type};{drift_action.__name__};{seq_len};{hidden_sizes};{loss};{mae_full};{mae_warmup}\\n\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06074ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98102d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, detector, x_all, y_all, seq_len, optimizer, loss_fn, device, drift_action):\n",
    "\n",
    "    model.train()\n",
    "    all_loss = []\n",
    "\n",
    "    # For drift action state\n",
    "    base_lrs = [pg['lr'] for pg in optimizer.param_groups]\n",
    "    decay_state = {\n",
    "        'base_lrs': base_lrs,\n",
    "        'current_decay_step': 0\n",
    "    }\n",
    "\n",
    "    step = 0\n",
    "    mae_values = []\n",
    "    mae_values_full = []\n",
    "\n",
    "    for x, y in zip(x_all, y_all):\n",
    "        step += 1\n",
    "        x_ten = torch.tensor(x, dtype=torch.float32).view(1, seq_len, -1).to(device)\n",
    "        y_ten = torch.tensor(y, dtype=torch.float32).view(1, -1).to(device)\n",
    "        # Training step\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_ten)\n",
    "        loss = loss_fn(pred, y_ten)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        all_loss.append(loss.item())\n",
    "\n",
    "        # Drift handling\n",
    "        if detector.update(loss.item()):\n",
    "            drift_action(optimizer, drifted=True, decay_state=decay_state)\n",
    "\n",
    "        drift_action(optimizer, drifted=False, decay_state=decay_state)\n",
    "        \n",
    "        mae_full = torch.abs(pred - y_ten).mean().item()\n",
    "        mae_values_full.append(mae_full)\n",
    "\n",
    "        # Post-warmup MAE tracking\n",
    "        if step >= 200:\n",
    "            mae_values.append(mae_full)\n",
    "\n",
    "    avg_loss = sum(all_loss) / len(all_loss) if all_loss else 0.0\n",
    "    avg_mae_post_warmup = sum(mae_values) / len(mae_values) if mae_values else 0.0\n",
    "    avg_mae_full = sum(mae_values_full) / len(mae_values_full) if mae_values_full else 0.0\n",
    "\n",
    "\n",
    "    return model, avg_loss, avg_mae_post_warmup, avg_mae_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbaaff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizess = [16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_water_flow_data()\n",
    "for detector_type in detector_types:\n",
    "    detector = DriftDetector(method=detector_type)\n",
    "    for drift_action in drift_actions:\n",
    "        for seq_len in seq_lens:\n",
    "            for hidden_sizes in hidden_sizess:\n",
    "                x_all, y_all = make_dataset(data, seq_len)\n",
    "                model = RNNModel(\n",
    "                    input_size=1,\n",
    "                    hidden_size=hidden_sizes,\n",
    "                    output_size=1,\n",
    "                    rnn_type='rnn'\n",
    "                )\n",
    "                model.to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                loss_fn = nn.MSELoss()\n",
    "                model, loss, mae_full, mae_warmup = train_model(\n",
    "                    model,\n",
    "                    detector,\n",
    "                    x_all,\n",
    "                    y_all,\n",
    "                    optimizer,\n",
    "                    loss_fn,\n",
    "                    device=device,\n",
    "                    drift_action=drift_action\n",
    "                )\n",
    "                # save stream, n_dim, n_points, detector_type, seq_len, hidden_sizes, train_loss, test_loss to CVS file\n",
    "                with open(\"wf_rnn.csv\", \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"{generate_water_flow_data.__name__};1;{len(data)};{detector_type};{drift_action.__name__};{seq_len};{hidden_sizes};{loss};{mae_full};{mae_warmup}\\n\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_water_flow_data()\n",
    "for detector_type in detector_types:\n",
    "    detector = DriftDetector(method=detector_type)\n",
    "    for drift_action in drift_actions:\n",
    "        for seq_len in seq_lens:\n",
    "            for hidden_sizes in hidden_sizess:\n",
    "                x_all, y_all = make_dataset(data, seq_len)\n",
    "                model = RNNModel(\n",
    "                    input_size=1,\n",
    "                    hidden_size=hidden_sizes,\n",
    "                    output_size=1,\n",
    "                    rnn_type='lstm'\n",
    "                )\n",
    "                model.to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                loss_fn = nn.MSELoss()\n",
    "                model, loss, mae_full, mae_warmup = train_model(\n",
    "                    model,\n",
    "                    detector,\n",
    "                    x_all,\n",
    "                    y_all,\n",
    "                    optimizer,\n",
    "                    loss_fn,\n",
    "                    device=device,\n",
    "                    drift_action=drift_action\n",
    "                )\n",
    "                # save stream, n_dim, n_points, detector_type, seq_len, hidden_sizes, train_loss, test_loss to CVS file\n",
    "                with open(\"wf_lstm.csv\", \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"{generate_water_flow_data.__name__};1;{len(data)};{detector_type};{drift_action.__name__};{seq_len};{hidden_sizes};{loss};{mae_full};{mae_warmup}\\n\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_models = [16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c85ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_water_flow_data()\n",
    "for detector_type in detector_types:\n",
    "    detector = DriftDetector(method=detector_type)\n",
    "    for drift_action in drift_actions:\n",
    "        for seq_len in seq_lens:\n",
    "            for d_model in d_models:\n",
    "                x_all, y_all = make_dataset(data, seq_len)\n",
    "                model = TimeSeriesTransformer(\n",
    "                    input_size=1,\n",
    "                    d_model=d_model,\n",
    "                    nhead=2,\n",
    "                    num_layers=2,\n",
    "                    output_size=1,\n",
    "                )\n",
    "                model.to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                loss_fn = nn.MSELoss()\n",
    "                model, loss, mae_full, mae_warmup = train_model(\n",
    "                    model,\n",
    "                    detector,\n",
    "                    x_all,\n",
    "                    y_all,\n",
    "                    optimizer,\n",
    "                    loss_fn,\n",
    "                    device=device,\n",
    "                    drift_action=drift_action\n",
    "                )\n",
    "                # save stream, n_dim, n_points, detector_type, seq_len, hidden_sizes, train_loss, test_loss to CVS file\n",
    "                with open(\"wf_lstm.csv\", \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"{generate_water_flow_data.__name__};1;{len(data)};{detector_type};{drift_action.__name__};{seq_len};{hidden_sizes};{loss};{mae_full};{mae_warmup}\\n\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be8bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a44ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6af523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e7597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
